# ğŸ“° Multi-Level News Classifier â€” TF-IDF vs BERT

This project compares two text classification approaches on the **AG News dataset**:
1. **Baseline:** TF-IDF + Logistic Regression  
2. **Advanced:** Fine-tuned BERT (`bert-base-uncased`)  

---

## ğŸ“Š Dataset
The [AG News dataset](https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset) contains **4 categories**:
- World  
- Sports  
- Business  
- Sci/Tech  

Each record has a *Title* and *Description* column.

---

## ğŸ“ Project Structure

```
news-classifier/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â””â”€â”€ test.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.html
â”‚   â”œâ”€â”€ 02_baseline_tfidf.html
â”‚   â””â”€â”€ 03_bert_finetune_clean.html
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ conf_matrix_tfidf.png
â”‚   â””â”€â”€ conf_matrix_bert.png
â””â”€â”€ README.md
```

---

## ğŸ“˜ Notebooks (clickable)

| Notebook | Description |
|-----------|--------------|
| [01_eda.html](notebooks/01_eda.html) | Exploratory Data Analysis |
| [02_baseline_tfidf.html](notebooks/02_baseline_tfidf.html) | TF-IDF Baseline Model |
| [03_bert_finetune_clean.html](notebooks/03_bert_finetune_clean.html) | Fine-Tuned BERT Model |

---

## ğŸ§  Model Comparison

| Metric | TF-IDF + Logistic Regression | BERT (Fine-Tuned) |
|:-------|:-----------------------------:|:-----------------:|
| Accuracy | **0.92** | **0.95** |
| Precision (avg) | 0.92 | 0.95 |
| Recall (avg) | 0.92 | 0.95 |
| F1-Score (avg) | 0.92 | 0.95 |
| Training Epochs | â€“ | 2 |
| Training Loss (last) | â€“ | 0.1120 |
| Validation Loss (last) | â€“ | 0.1886 |

---

## ğŸ“ˆ Confusion Matrices

| TF-IDF | BERT |
|:------:|:----:|
| ![TF-IDF Confusion Matrix](reports/conf_matrix_tfidf.png) | ![BERT Confusion Matrix](reports/conf_matrix_bert.png) |

---

## ğŸ§© Evaluation Reports

### BERT Report
```
          precision    recall  f1-score   support

   World       0.96      0.96      0.96      1900
  Sports       0.99      0.99      0.99      1900
Business       0.93      0.91      0.92      1900
Sci/Tech       0.91      0.94      0.92      1900

accuracy                           0.95      7600

```
